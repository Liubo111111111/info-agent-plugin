---
name: x-digest
description: "从 X (Twitter) 列表抓取 AI/LLM 相关内容，筛选后生成 3-5 条精选摘要报告，并记录到 cache.json 防止重复推荐。"
allowed-tools: Read, Write, Shell(mkdir*)
---

# X (Twitter) AI Digest

从指定的 X (Twitter) 列表抓取 AI/LLM 相关内容，筛选后生成精选摘要报告。专注于 Twitter 上的高质量内容发现和推荐。

**注意**：本 skill 专注于 X/Twitter 内容。HackerNews 内容由 `daily-news-report` skill 处理。

## 共享规范

**重要**：本 skill 引用以下共享模块：

| 模块 | 用途 |
|------|------|
| [`../../_shared/format-spec.md`](../../_shared/format-spec.md) | 输出格式规范 |
| [`../../_shared/browser-utils.md`](../../_shared/browser-utils.md) | 浏览器抓取工具 |
| [`../../_shared/dedup-scoring.md`](../../_shared/dedup-scoring.md) | 去重与评分逻辑 |
| [`../../_shared/cache-schema.json`](../../_shared/cache-schema.json) | 缓存文件 Schema |

## 不适用场景

- 抓取需要登录的 X 私密列表
- 非 AI/LLM 相关内容聚合
- 实时监控（本 skill 为批量生成）
- 超过 50 条的大批量抓取
- 需要实时推送（本 skill 生成本地报告）
- HackerNews 内容抓取（使用 `daily-news-report`）

## 如何启动

用户可以通过以下方式触发此 skill：

```
生成今日 X AI 摘要
抓取 X 列表的 AI 内容
帮我看看 Twitter 上有什么 AI 新闻
```

## 步骤 0：前置检查

验证配置文件存在（skill 目录：`.info-agent-plugin/info-skills/x-digest/`）：

| 文件 | 用途 | 必需 |
|------|------|------|
| [`sources.json.example`](sources.json.example) | X 列表配置 | 是 |
| [`cache.json.example`](cache.json.example) | 缓存数据、URL 去重 | 是 |

验证输出目录：
- `output_info/` - 摘要输出目录（如不存在则创建）

**如果配置文件不存在**：停止并告知用户配置缺失。
如果 `sources.json` 缺失：从 [`sources.json.example`](sources.json.example) 复制并填写。

## 步骤 1：初始化

1. **强制要求 - 阅读配置**：完整阅读 [`sources.json.example`](sources.json.example) 了解：
   - X 列表 URL 和启用状态
   - 质量评分权重
   
2. 确定目标日期（当前日期，格式：`YYYY-MM-DD`）

3. 读取 [`cache.json.example`](cache.json.example) 检查：
   - `url_cache` - 已处理的 URL（用于去重）
   - `content_hashes` - 内容指纹
   - `digest_history` - 历史摘要记录
4. 若存在 `EXTEND.md`，读取并将其作为补充执行规则

## 步骤 2：抓取 X 列表

按照 [`../../_shared/browser-utils.md`](../../_shared/browser-utils.md) 第 5.3 节规范抓取 X 列表。

### 本 Skill 特定配置

1. **时间窗口**：过去 24 小时内的帖子
2. **数量限制**：每个列表最多 50 条
3. **筛选条件**：
   - 包含 AI/LLM/ML 相关关键词
   - 排除纯转发（无评论的 RT）
   - 排除广告/推广内容

### 提取字段

| 字段 | 说明 | 示例 |
|------|------|------|
| author | 用户名 | @karpathy |
| content | 帖子内容 | "Just released..." |
| url | 帖子链接 | https://x.com/xxx/status/xxx |
| likes | 点赞数 | 1.2k |
| retweets | 转发数 | 500 |
| timestamp | 发布时间 | 3h |

**注意**：X 列表需要登录才能访问，如果抓取失败，记录错误并提示用户。

## 步骤 3：去重与筛选

按照 [`../../_shared/dedup-scoring.md`](../../_shared/dedup-scoring.md) 规范执行去重和评分。

### 本 Skill 特定配置

**去重规则**（优先级顺序）：

| 优先级 | 方法 | 说明 |
|--------|------|------|
| 1 | URL 去重 | 检查 `cache.json` 的 `url_cache` |
| 2 | 内容相似度 | 标题相似度 > 80% 视为重复 |

**质量筛选标准**：

- **保留**：AI/LLM 技术突破、新模型/工具发布、实用开源项目、深度技术分析
- **排除**：纯营销/推广、过度炒作标题党、重复新闻、低质量讨论

**评分计算**（详见 dedup-scoring.md）：

```
score = base_score + engagement_bonus + keyword_bonus
```

其中 `engagement_bonus` 根据 X likes/retweets 计算。

## 步骤 4：生成摘要报告

从筛选后的内容中选取 **3-5 条** 最高质量的内容，生成本地报告文件。

### 输出路径

`output_info/YYYY-MM-DD-x-digest.md`

### 报告格式

遵循 [`../../_shared/format-spec.md`](../../_shared/format-spec.md) 中定义的统一格式：

```markdown
# X (Twitter) AI Digest（YYYY-MM-DD）

> 本日筛选自 X Lists，共收录 N 条高质量内容

---

## 1. 帖子标题/摘要

- **摘要**：2-3 句话概述帖子核心内容和价值
- **要点**：
  1. 关键要点一
  2. 关键要点二
  3. 关键要点三
- **来源**：[X @用户名](https://x.com/xxx/status/xxx)
- **关键词**：`AI` `LLM` `OpenAI`
- **评分**：⭐⭐⭐⭐⭐ (5/5)
- **热度**：1.2k likes | 500 retweets

---

## 2. 帖子标题/摘要
...

---

## 其他推荐

| 排名 | 标题 | 热度 | 来源 |
|------|------|------|------|
| N+1 | [标题](URL) | 500 likes | X |

---

*Generated by X Digest*
*Date: YYYY-MM-DD*
```

## 步骤 5：更新记录

### 更新 cache.json

按照 [`../../_shared/cache-schema.json`](../../_shared/cache-schema.json) 规范更新缓存：

```json
{
  "last_run": {
    "date": "YYYY-MM-DD",
    "timestamp": "ISO时间戳",
    "x_items_fetched": 30,
    "items_included": 5,
    "errors": []
  },
  "url_cache": {
    "ttl_days": 7,
    "entries": {
      "https://x.com/xxx/status/xxx": "YYYY-MM-DD"
    }
  }
}
```

## 步骤 6：失败处理

### X 列表抓取失败

1. 记录错误到 `cache.json` 的 `errors` 数组
2. 跳过该列表，继续其他列表
3. 如果所有 X 列表失败，提示用户检查登录状态或网络连接

### 内容不足

如果筛选后内容少于 3 条：
1. 降低筛选标准（评分 >= 3 改为 >= 2）
2. 扩大时间窗口（24h 改为 48h）
3. 如果仍不足，生成现有内容并在报告中说明

## 配置文件说明

### sources.json 结构

```json
{
  "x_lists": {
    "lists": [
      {"id": "ai_researchers", "name": "AI Researchers", "url": "...", "enabled": true}
    ],
    "fetch_config": {"max_posts_per_list": 50, "time_window_hours": 24}
  },
  "digest": {
    "min_items": 3,
    "max_items": 5,
    "min_quality_score": 3
  },
  "quality_weights": {
    "x_likes": 0.005,
    "x_retweets": 0.01
  }
}
```

### cache.json 结构

```json
{
  "last_run": {"date": "...", "items_sent": 5},
  "url_cache": {"entries": {"url": "date"}},
  "content_hashes": {"entries": {}},
  "digest_history": {"entries": []}
}
```

## 约束与原则

1. **精选优先**：只输出 3-5 条最高质量内容，宁缺毋滥
2. **去重严格**：绝不重复推荐已发送过的内容（基于 cache.json）
3. **时效性**：只抓取 24-48 小时内内容
4. **失败容错**：单个源失败不影响整体流程
5. **记录完整**：所有推荐都记录到 cache.json
6. **格式统一**：报告格式与其他 skill 保持一致

## 依赖项

- **WebFetch**：用于抓取页面内容（注意：需要 JS 渲染的页面可能无法完整抓取）
- **Read/Write 工具**：用于读取配置和生成报告

## 快速参考

| 场景 | 操作 |
|------|------|
| 生成今日摘要 | 执行完整流程 |
| 扩大时间范围 | 修改 sources.json 的 time_window_hours |
| 调整输出数量 | 修改 sources.json 的 min_items/max_items |
| 添加新列表 | 在 sources.json 的 x_lists.lists 中添加 |






